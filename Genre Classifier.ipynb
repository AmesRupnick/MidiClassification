{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9013dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rupni\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1069afc8",
   "metadata": {},
   "source": [
    "Get the Genre and File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32141b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Genre             TrackID\n",
      "0  Pop_Rock  TRAAAAK128F9318786\n",
      "1       Rap  TRAAAAW128F429D538\n",
      "2  Pop_Rock  TRAAABD128F429CF47\n",
      "3      Jazz  TRAAAED128E0783FAB\n",
      "4  Pop_Rock  TRAAAEF128F4273421\n",
      "\n",
      "['New Age', 'Jazz', 'Reggae', 'Latin', 'Electronic', 'Pop_Rock', 'Folk', 'RnB', 'International', 'Country', 'Blues', 'Vocal', 'Rap']\n",
      "\n",
      "{'New Age': 1, 'Jazz': 2, 'Reggae': 3, 'Latin': 4, 'Electronic': 5, 'Pop_Rock': 6, 'Folk': 7, 'RnB': 8, 'International': 9, 'Country': 10, 'Blues': 11, 'Vocal': 12, 'Rap': 13}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_genres(path):\n",
    "    \"\"\"\n",
    "    This function reads the genre labels and puts it into a pandas DataFrame.\n",
    "    \n",
    "    @input path: The path to the genre label file.\n",
    "    @type path: String\n",
    "    \n",
    "    @return: A pandas dataframe containing the genres and midi IDs.\n",
    "    @rtype: pandas.DataFrame\n",
    "    \"\"\"\n",
    "    ids = []\n",
    "    genres = []\n",
    "    with open(path) as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            if line[0] != '#':\n",
    "                [x, y, *_] = line.strip().split(\"\\t\")\n",
    "                ids.append(x)\n",
    "                genres.append(y)\n",
    "            line = f.readline()\n",
    "    genre_df = pd.DataFrame(data={\"Genre\": genres, \"TrackID\": ids})\n",
    "    return genre_df\n",
    "\n",
    "# Get the Genre DataFrame\n",
    "genre_path = \"msd_tagtraum_cd1.cls\"\n",
    "genre_df = get_genres(genre_path)\n",
    "\n",
    "# Create Genre List and Dictionary\n",
    "label_list = list(set(genre_df.Genre))\n",
    "label_dict = {lbl: label_list.index(lbl) + 1 for lbl in label_list}\n",
    "\n",
    "# Print to Visualize\n",
    "print(genre_df.head(), end=\"\\n\\n\")\n",
    "print(label_list, end=\"\\n\\n\")\n",
    "print(label_dict, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099516e0",
   "metadata": {},
   "source": [
    "Match the Midi to the Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93ba713c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Path     Genre\n",
      "0  lmd_matched\\A\\A\\A\\TRAAAGR128F425B14B/1d9d16a9d...  Pop_Rock\n",
      "1  lmd_matched\\A\\A\\A\\TRAAAGR128F425B14B/5dd29e99e...  Pop_Rock\n",
      "2  lmd_matched\\A\\A\\A\\TRAAAGR128F425B14B/b97c529ab...  Pop_Rock\n",
      "3  lmd_matched\\A\\A\\A\\TRAAAGR128F425B14B/dac3cdd0d...  Pop_Rock\n",
      "4  lmd_matched\\A\\A\\D\\TRAADKW128E079503A/3797e9b9a...  Pop_Rock\n"
     ]
    }
   ],
   "source": [
    "def get_matched_midi(midi_folder, genre_df):\n",
    "    \"\"\"\n",
    "    This function loads in midi file paths that are found in the given folder, puts this data into a\n",
    "    pandas DataFrame, then matches each entry with a genre described in get_genres.\n",
    "    \n",
    "    @input midi_folder: The path to the midi files.\n",
    "    @type midi_folder: String\n",
    "    @input genre_df: The genre label dataframe generated by get_genres.\n",
    "    @type genre_df: pandas.DataFrame\n",
    "    \n",
    "    @return: A dataframe of track id and path to a midi file with that track id.\n",
    "    @rtype: pandas.DataFrame\n",
    "    \"\"\"\n",
    "    # Get All Midi Files\n",
    "    track_ids, file_paths = [], []\n",
    "    #print(midi_folder)\n",
    "    for dir_name, subdir_list, file_list in os.walk(midi_folder):\n",
    "        if len(dir_name) == 36:\n",
    "            track_id = dir_name[18:]\n",
    "            file_path_list = [\"/\".join([dir_name, file]) for file in file_list]\n",
    "            for file_path in file_path_list:\n",
    "                track_ids.append(track_id)\n",
    "                file_paths.append(file_path)\n",
    "    all_midi_df = pd.DataFrame({\"TrackID\": track_ids, \"Path\": file_paths})\n",
    "    \n",
    "    # Inner Join with Genre Dataframe\n",
    "    df = pd.merge(all_midi_df, genre_df, on='TrackID', how='inner')\n",
    "    return df.drop([\"TrackID\"], axis=1)\n",
    "\n",
    "# Obtain DataFrame with Matched Genres to File Paths\n",
    "midi_path = \"lmd_matched\"\n",
    "matched_midi_df = get_matched_midi(midi_path, genre_df)\n",
    "\n",
    "# Print to Check Correctness\n",
    "print(matched_midi_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2282b35",
   "metadata": {},
   "source": [
    "With Only Midi Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e57796de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 67, 835, 77, 299, 10599, 126, 456, 33, 276, 1182, 96, 348, 42]\n"
     ]
    }
   ],
   "source": [
    "import pretty_midi\n",
    "import warnings\n",
    "\n",
    "note_total = 324\n",
    "i = 0\n",
    "count = [0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "with open('midi_info_start.txt', 'w') as f_start, \\\n",
    "     open('midi_info_end.txt', 'w') as f_end, \\\n",
    "     open('midi_info_pitch.txt', 'w') as f_pitch, \\\n",
    "     open('midi_info_velocity.txt', 'w') as f_velocity:\n",
    "    \n",
    "    for index, row in matched_midi_df.iterrows():\n",
    "        #print(row.Path)\n",
    "        \n",
    "        genre = label_dict[row.Genre]\n",
    "        if genre is not None:\n",
    "            count[genre] = count[genre] + 1\n",
    "            #if count[genre] > 1000:\n",
    "                #continue\n",
    "            \n",
    "        try:\n",
    "            # Test for Corrupted Midi Files\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"error\")\n",
    "                file = pretty_midi.PrettyMIDI(row.Path)\n",
    "                notecount = 0\n",
    "                for i, instrument in enumerate(file.instruments):\n",
    "                    if i >= 1:\n",
    "                        break\n",
    "                    for index, note in enumerate(instrument.notes):\n",
    "                        if index >= note_total:\n",
    "                            break;\n",
    "                        if index != note_total - 1:\n",
    "                            f_start.write(f\"{note.start},\")\n",
    "                            f_end.write(f\"{note.end},\")\n",
    "                            f_pitch.write(f\"{note.pitch},\")\n",
    "                            f_velocity.write(f\"{note.velocity},\")\n",
    "                        else:\n",
    "                            f_start.write(f\"{note.start},{label_dict[row.Genre]}\\n\")\n",
    "                            f_end.write(f\"{note.end}\\n\")\n",
    "                            f_pitch.write(f\"{note.pitch}\\n\")\n",
    "                            f_velocity.write(f\"{note.velocity}\\n\")\n",
    "                        notecount += 1\n",
    "                        \n",
    "                    #checks for if song is less than 100 notes, will fill with zeros if so\n",
    "                    while notecount < note_total:\n",
    "                        if notecount != note_total - 1:\n",
    "                            f_start.write(f\"{0},\")\n",
    "                            f_end.write(f\"{0},\")\n",
    "                            f_pitch.write(f\"{0},\")\n",
    "                            f_velocity.write(f\"{0},\")\n",
    "                        else:\n",
    "                            f_start.write(f\"{0},{label_dict[row.Genre]}\\n\")\n",
    "                            f_end.write(f\"{0}\\n\")\n",
    "                            f_pitch.write(f\"{0}\\n\")\n",
    "                            f_velocity.write(f\"{0}\\n\")\n",
    "                        notecount += 1\n",
    "        except:\n",
    "            continue\n",
    "        i += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662d5f03",
   "metadata": {},
   "source": [
    "No Notes Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5555278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 276, 299, 77, 348, 835, 10599, 67, 456, 96, 1182, 33, 42, 126]\n"
     ]
    }
   ],
   "source": [
    "#This form includes the features included in the orginal project, with song length and pitch classes included\n",
    "i = 0\n",
    "count = [0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "with open('midi_info_small.txt', 'w') as output_file:\n",
    "    for index, row in matched_midi_df.iterrows():\n",
    "        #print(row.Path)\n",
    "        \n",
    "        genre = label_dict[row.Genre]\n",
    "        if genre is not None:\n",
    "            count[genre] = count[genre] + 1\n",
    "            #if count[genre] > 1000:\n",
    "                #continue\n",
    "            \n",
    "        try:\n",
    "            # Test for Corrupted Midi Files\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"error\")\n",
    "                file = pretty_midi.PrettyMIDI(row.Path)\n",
    "\n",
    "                tempo = file.estimate_tempo()\n",
    "                num_sig_changes = len(file.time_signature_changes)\n",
    "                resolution = file.resolution\n",
    "                ts_changes = file.time_signature_changes\n",
    "                ts_1 = 4\n",
    "                ts_2 = 4\n",
    "                if len(ts_changes) > 0:\n",
    "                    ts_1 = ts_changes[0].numerator\n",
    "                    ts_2 = ts_changes[0].denominator\n",
    "                song_length = file.get_end_time()\n",
    "                pitch_class = file.get_pitch_class_histogram()\n",
    "                \n",
    "                output_file.write(f'{tempo},{num_sig_changes},{resolution},{ts_1},{ts_2},{song_length},{pitch_class[0]},{pitch_class[1]},{pitch_class[2]},{pitch_class[3]},{pitch_class[4]},{pitch_class[5]},{pitch_class[6]},{pitch_class[7]},{pitch_class[8]},{pitch_class[9]},{pitch_class[10]},{pitch_class[11]},{label_dict[row.Genre]}\\n')\n",
    "        except:\n",
    "            continue\n",
    "        i = i + 1  \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8159f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.24177919e+02 1.00000000e+00 1.92000000e+02 ... 8.12064965e-03\n",
      "  5.68445476e-02 6.00000000e+00]\n",
      " [2.41150166e+02 2.00000000e+00 4.80000000e+02 ... 0.00000000e+00\n",
      "  1.06518283e-01 6.00000000e+00]\n",
      " [2.57689352e+02 1.00000000e+00 4.80000000e+02 ... 0.00000000e+00\n",
      "  4.00219298e-02 6.00000000e+00]\n",
      " ...\n",
      " [1.78799540e+02 1.00000000e+00 3.84000000e+02 ... 5.31914894e-03\n",
      "  2.57812500e-01 6.00000000e+00]\n",
      " [1.70264635e+02 1.00000000e+00 4.80000000e+02 ... 2.33488993e-02\n",
      "  4.66977985e-02 8.00000000e+00]\n",
      " [1.70264635e+02 1.00000000e+00 4.80000000e+02 ... 2.33488993e-02\n",
      "  4.66977985e-02 8.00000000e+00]]\n",
      "(13520, 19)\n"
     ]
    }
   ],
   "source": [
    "with open('midi_info_small.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "    # Convert the lines to a NumPy array\n",
    "    simple_features = np.loadtxt(lines, delimiter=',')\n",
    "    print(simple_features)\n",
    "    print(simple_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22e7f010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Features Array:\n",
      " [[1.82291667e-02 2.55208333e-01 5.05208333e-01 ... 1.12255208e+02\n",
      "  1.12505208e+02 1.12731771e+02]\n",
      " [1.98346800e+00 1.98346800e+00 1.98346800e+00 ... 2.10743475e+01\n",
      "  2.11983142e+01 2.13222810e+01]\n",
      " [1.96718400e+00 2.21308200e+00 2.33603100e+00 ... 7.57365840e+01\n",
      "  7.59824820e+01 7.61054310e+01]\n",
      " ...\n",
      " [3.06130089e+00 3.05732000e+00 3.05732000e+00 ... 2.92316416e+01\n",
      "  2.92356225e+01 2.92316416e+01]\n",
      " [2.06896500e+00 2.11948617e+02 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.06896500e+00 2.11948617e+02 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]] \n",
      "\n",
      "Start Features Shape: (13520, 324) \n",
      "\n",
      "End Features Array:\n",
      " [[1.84895833e-01 4.37500000e-01 6.87500000e-01 ... 1.12437500e+02\n",
      "  1.12687500e+02 1.12869792e+02]\n",
      " [2.06301333e+00 2.06301333e+00 2.07231084e+00 ... 2.11084384e+01\n",
      "  2.12324051e+01 2.13563719e+01]\n",
      " [2.02968307e+00 2.26226160e+00 2.39033347e+00 ... 7.57990831e+01\n",
      "  7.60316616e+01 7.61597335e+01]\n",
      " ...\n",
      " [6.00715609e+00 6.01113698e+00 6.01511786e+00 ... 2.93510682e+01\n",
      "  2.93510682e+01 2.93590299e+01]\n",
      " [2.75862000e+00 2.12638272e+02 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.75862000e+00 2.12638272e+02 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]] \n",
      "\n",
      "End Features Shape: (13520, 324) \n",
      "\n",
      "Pitch Features Array:\n",
      " [[69. 76. 74. ... 76. 74. 72.]\n",
      " [65. 69. 35. ... 70. 70. 70.]\n",
      " [69. 69. 69. ... 69. 69. 69.]\n",
      " ...\n",
      " [59. 56. 52. ... 52. 56. 47.]\n",
      " [48. 48.  0. ...  0.  0.  0.]\n",
      " [48. 48.  0. ...  0.  0.  0.]] \n",
      "\n",
      "Pitch Features Shape: (13520, 324) \n",
      "\n",
      "Velocity Features Array:\n",
      " [[100. 100. 100. ... 100. 100. 100.]\n",
      " [ 61.  61.  91. ...  65.  65.  63.]\n",
      " [107. 107.  89. ... 107. 107.  89.]\n",
      " ...\n",
      " [ 96.  95.  91. ...  88.  90.  82.]\n",
      " [127. 127.   0. ...   0.   0.   0.]\n",
      " [127. 127.   0. ...   0.   0.   0.]] \n",
      "\n",
      "Velocity Features Shape: (13520, 324) \n",
      "\n",
      "Genre Labels:\n",
      " [[5.]\n",
      " [5.]\n",
      " [5.]\n",
      " ...\n",
      " [5.]\n",
      " [7.]\n",
      " [7.]] \n",
      "\n",
      "Genre Labels Shape: (13520, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parser(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "     # Convert the lines to a NumPy array\n",
    "    labeled_features = np.loadtxt(lines, delimiter=',')\n",
    "    return labeled_features\n",
    "\n",
    "features_start = parser(\"midi_info_start.txt\")\n",
    "features_end = parser(\"midi_info_end.txt\")\n",
    "features_pitch = parser(\"midi_info_pitch.txt\")\n",
    "features_velocity = parser(\"midi_info_velocity.txt\")\n",
    "\n",
    "num_columns = features_start.shape[1] - 1\n",
    "\n",
    "genre_labels = features_start[:, num_columns]\n",
    "genre_labels = np.reshape(genre_labels, (len(genre_labels), 1))\n",
    "\n",
    "features_start = features_start[:, :num_columns]\n",
    "#features_start = np.delete(features_start, num_columns, axis=1)\n",
    "\n",
    "print(\"Start Features Array:\\n\", features_start,\"\\n\")\n",
    "print(\"Start Features Shape:\", features_start.shape,\"\\n\")\n",
    "\n",
    "print(\"End Features Array:\\n\", features_end,\"\\n\")\n",
    "print(\"End Features Shape:\", features_end.shape,\"\\n\")\n",
    "\n",
    "print(\"Pitch Features Array:\\n\", features_pitch,\"\\n\")\n",
    "print(\"Pitch Features Shape:\", features_pitch.shape,\"\\n\")\n",
    "\n",
    "print(\"Velocity Features Array:\\n\", features_velocity,\"\\n\")\n",
    "print(\"Velocity Features Shape:\", features_velocity.shape,\"\\n\")\n",
    "\n",
    "print(\"Genre Labels:\\n\", genre_labels,\"\\n\")\n",
    "print(\"Genre Labels Shape:\", genre_labels.shape,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f84d12b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Features Array:\n",
      " [[  2.823528     3.882351     3.176469   ...  80.470548    80.470548\n",
      "   81.529371  ]\n",
      " [  0.           0.6          1.2        ...   0.           0.\n",
      "    0.        ]\n",
      " [ 10.68964733  10.862061    11.20688833 ... 144.82748    145.17230733\n",
      "  145.68954833]\n",
      " ...\n",
      " [  0.25         0.5          0.         ...   0.           0.\n",
      "    0.        ]\n",
      " [  2.142858     2.142858     2.500001   ...  43.928589    43.928589\n",
      "   44.1071605 ]\n",
      " [  1.951216     2.195118     2.43902    ...   0.           0.\n",
      "    0.        ]] \n",
      "\n",
      "Start Features Shape: (13520, 324) \n",
      "\n",
      "End Features Array:\n",
      " [[  4.22646847   4.22646847   4.22646847 ...  81.529371    81.529371\n",
      "   82.57937047]\n",
      " [  0.475        1.05         1.575      ...   0.           0.\n",
      "    0.        ]\n",
      " [ 10.82757827  11.13792287  11.34481927 ... 145.10334187 145.58610013\n",
      "  146.10334113]\n",
      " ...\n",
      " [  0.5          0.75         4.         ...   0.           0.\n",
      "    0.        ]\n",
      " [  2.21726279   2.21726279   2.57440579 ...  44.00299379  44.00299379\n",
      "   44.18156529]\n",
      " [  2.16463025   2.43139806   2.64735296 ...   0.           0.\n",
      "    0.        ]] \n",
      "\n",
      "End Features Shape: (13520, 324) \n",
      "\n",
      "Pitch Features Array:\n",
      " [[67. 67. 63. ... 60. 57. 63.]\n",
      " [33. 33. 33. ...  0.  0.  0.]\n",
      " [66. 68. 66. ... 68. 76. 71.]\n",
      " ...\n",
      " [57. 60. 45. ...  0.  0.  0.]\n",
      " [46. 35. 37. ... 42. 35. 42.]\n",
      " [65. 60. 64. ...  0.  0.  0.]] \n",
      "\n",
      "Pitch Features Shape: (13520, 324) \n",
      "\n",
      "Velocity Features Array:\n",
      " [[ 75.  75.  75. ...  75.  75.  75.]\n",
      " [127. 127. 127. ...   0.   0.   0.]\n",
      " [117. 123. 100. ... 102. 100.  98.]\n",
      " ...\n",
      " [ 95.  95.  95. ...   0.   0.   0.]\n",
      " [ 90. 100.  80. ...  90. 100.   1.]\n",
      " [ 78.  62.  83. ...   0.   0.   0.]] \n",
      "\n",
      "Velocity Features Shape: (13520, 324) \n",
      "\n",
      "Genre Labels:\n",
      " [[ 5.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " ...\n",
      " [ 5.]\n",
      " [10.]\n",
      " [ 5.]] \n",
      "\n",
      "Genre Labels Shape: (13520, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the number of rows in the arrays\n",
    "num_rows = features_start.shape[0]\n",
    "\n",
    "# Shuffle indices\n",
    "indices = np.random.permutation(num_rows)\n",
    "\n",
    "# Use shuffled indices to reorder both arrays\n",
    "features_start = features_start[indices]\n",
    "features_end = features_end[indices]\n",
    "features_pitch = features_pitch[indices]\n",
    "features_velocity = features_velocity[indices]\n",
    "genre_labels = genre_labels[indices]\n",
    "\n",
    "print(\"Start Features Array:\\n\", features_start,\"\\n\")\n",
    "print(\"Start Features Shape:\", features_start.shape,\"\\n\")\n",
    "\n",
    "print(\"End Features Array:\\n\", features_end,\"\\n\")\n",
    "print(\"End Features Shape:\", features_end.shape,\"\\n\")\n",
    "\n",
    "print(\"Pitch Features Array:\\n\", features_pitch,\"\\n\")\n",
    "print(\"Pitch Features Shape:\", features_pitch.shape,\"\\n\")\n",
    "\n",
    "print(\"Velocity Features Array:\\n\", features_velocity,\"\\n\")\n",
    "print(\"Velocity Features Shape:\", features_velocity.shape,\"\\n\")\n",
    "\n",
    "print(\"Genre Labels:\\n\", genre_labels,\"\\n\")\n",
    "print(\"Genre Labels Shape:\", genre_labels.shape,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a46f4761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Features Shape: (13520, 324) \n",
      "\n",
      "End Features Shape: (13520, 324) \n",
      "\n",
      "Pitch Features Shape: (13520, 324) \n",
      "\n",
      "Velocity Features Shape: (13520, 324) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Scalar from SKLearn library\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform data\n",
    "features_start = scaler.fit_transform(features_start)\n",
    "features_end = scaler.fit_transform(features_end)\n",
    "features_pitch = scaler.fit_transform(features_pitch)\n",
    "features_velocity = scaler.fit_transform(features_velocity)\n",
    "\n",
    "#print(\"Start Features Array:\\n\", features_start,\"\\n\")\n",
    "print(\"Start Features Shape:\", features_start.shape,\"\\n\")\n",
    "\n",
    "#print(\"End Features Array:\\n\", features_end,\"\\n\")\n",
    "print(\"End Features Shape:\", features_end.shape,\"\\n\")\n",
    "\n",
    "#print(\"Pitch Features Array:\\n\", features_pitch,\"\\n\")\n",
    "print(\"Pitch Features Shape:\", features_pitch.shape,\"\\n\")\n",
    "\n",
    "#print(\"Velocity Features Array:\\n\", features_velocity,\"\\n\")\n",
    "print(\"Velocity Features Shape:\", features_velocity.shape,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cdc85ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x: (10816, 4, 18, 18) \n",
      "\n",
      "train_set_y: (10816, 1) \n",
      "\n",
      "test_set_x: (2704, 4, 18, 18) \n",
      "\n",
      "test_set_y: (2704, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit all data together into multidimensional array\n",
    "train_dataset = np.stack((features_start, features_end, features_pitch, features_velocity), axis=2)\n",
    "\n",
    "num_rows = features_start.shape[0]\n",
    "train_dataset = train_dataset.reshape((num_rows, 18, 18, 4))\n",
    "\n",
    "# Split data into training and testing data\n",
    "num = len(train_dataset)\n",
    "#num_training = int(num * 0.6)\n",
    "#num_validation = int(num * 0.8)\n",
    "num_training = int(num * 0.8)\n",
    "num_validation = int(num)\n",
    "\n",
    "train_set_x = train_dataset[:num_training]\n",
    "train_set_y = genre_labels[:num_training]\n",
    "test_set_x = train_dataset[num_training:num_validation]\n",
    "test_set_y = genre_labels[num_training:num_validation]\n",
    "\n",
    "# Shape to properly fit CNN model\n",
    "train_set_x = np.transpose(train_set_x, (0,3,1,2))\n",
    "test_set_x = np.transpose(test_set_x, (0,3,1,2))\n",
    "\n",
    "#print(\"train_set_x:\\n\", train_set_x,\"\\n\")\n",
    "print(\"train_set_x:\", train_set_x.shape,\"\\n\")\n",
    "\n",
    "#print(\"train_set_y:\\n\", train_set_y,\"\\n\")\n",
    "print(\"train_set_y:\", train_set_y.shape,\"\\n\")\n",
    "\n",
    "#print(\"test_set_x:\\n\", test_set_x,\"\\n\")\n",
    "print(\"test_set_x:\", test_set_x.shape,\"\\n\")\n",
    "\n",
    "#print(\"test_set_y:\\n\", test_set_y,\"\\n\")\n",
    "print(\"test_set_y:\", test_set_y.shape,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebd0169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  torch.Size([10816, 4, 18, 18]) torch.Size([10816, 1])\n",
      "Testing shape:   torch.Size([2704, 4, 18, 18]) torch.Size([2704, 1])\n"
     ]
    }
   ],
   "source": [
    "# Change to tensors\n",
    "train_set_x = torch.tensor(train_set_x, dtype=torch.float32)#.unsqueeze(dim=0)\n",
    "test_set_x = torch.tensor(test_set_x, dtype=torch.float32)#.unsqueeze(dim=0)\n",
    "train_set_y = torch.tensor(train_set_y, dtype=torch.float32)\n",
    "test_set_y = torch.tensor(test_set_y, dtype=torch.float32)\n",
    "\n",
    "print(\"Training shape: \", train_set_x.shape, train_set_y.shape)\n",
    "print(\"Testing shape:  \", test_set_x.shape, test_set_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e69453b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network (two convolutional layers)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(4, 16, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU())\n",
    "        self.fc2 = nn.Linear(128, 14)\n",
    "        #self.fc2 = nn.Sequential(\n",
    "            #nn.Linear(128, 14),\n",
    "            #nn.Softmax(dim=1))\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4133815e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Linear(in_features=128, out_features=14, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "136ff043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_y: torch.Size([10816]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_set_y = train_set_y.squeeze(dim=1).long()\n",
    "print(\"train_set_y:\", train_set_y.shape,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc85ba82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [250/1000], Loss: 1.0954\n",
      "Epoch [500/1000], Loss: 1.0826\n",
      "Epoch [750/1000], Loss: 1.0729\n",
      "Epoch [1000/1000], Loss: 1.0639\n"
     ]
    }
   ],
   "source": [
    "# Create model instance\n",
    "model = CNN()\n",
    "\n",
    "#set up objects needed for training\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(train_set_x)\n",
    "    loss = criterion(outputs, train_set_y.long())\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch == 249 or epoch == 499 or epoch == 749 or epoch == 999:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6ec7b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7226331360946746\n"
     ]
    }
   ],
   "source": [
    "# Test and check accuracy\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    outputs = model(test_set_x)\n",
    "    _, y_pred = torch.max(outputs, 1)\n",
    "    accuracy = accuracy_score(test_set_y.numpy(), y_pred.numpy())\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59afed7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (10816, 18)\n",
      "X_test shape: (2704, 18)\n",
      "y_train shape: (10816,)\n",
      "y_test shape: (2704,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "num_columns = labeled_features.shape[1] - 1\n",
    "simple_features = np.random.permutation(simple_features)\n",
    "\n",
    "X = simple_features[:, :num_columns]\n",
    "y = simple_features[:, num_columns].astype(int)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "    \n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting arrays\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a21b8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7732988165680473\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a decision tree classifier object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier using your training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of unseen data\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be3b7de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the NN None: 0.7267011834319527\n",
      "\n",
      "Accuracy of the NN None: 0.724112426035503\n",
      "\n",
      "Accuracy of the NN None: 0.7263313609467456\n",
      "\n",
      "Accuracy of the NN None: 0.742603550295858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_variable_name(variable):\n",
    "    for name, value in globals().items():\n",
    "        if value is variable:\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "def train_and_test(clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions = clf.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    clf_name = get_variable_name(clf)\n",
    "    print(f\"Accuracy of the NN {clf_name}: {accuracy}\\n\")\n",
    "\n",
    "def train_model(t_features, t_labels, v_features, v_labels):\n",
    "    #This function trains a neural network using a couple different configurations.\n",
    "    \n",
    "    # Neural Network Configurations\n",
    "    clf_1 = MLPClassifier(solver='adam', alpha=1e-4, hidden_layer_sizes=(5,), random_state=1)\n",
    "    clf_2 = MLPClassifier(solver='adam', alpha=1e-4, hidden_layer_sizes=(5, 5), random_state=1)\n",
    "    clf_3 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(10, 10), random_state=1)\n",
    "    clf_4 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(100, 100), random_state=1)\n",
    "    \n",
    "    \n",
    "    train_and_test(clf_1)\n",
    "    train_and_test(clf_2)\n",
    "    train_and_test(clf_3)\n",
    "    train_and_test(clf_4)\n",
    "    \n",
    "#classifier = train_model(training_features, training_labels, validation_features, validation_labels)\n",
    "classifier = train_model(X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
